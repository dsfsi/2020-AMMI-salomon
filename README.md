Speech to text translation in low resource Setting : LiSTra
============================================================

In this work we would like investigate the effectiveness of end-to-end architecture in opposite to pipeline approach by using the a transformer like architecture \cite{liu2019synchronous} and a custom attention mechanism that will weight both the speech recognition decoder with the translation decoder.

The used dataset is constructed following instructions in this repository [https://github.com/Kabongosalomon/LiSTra](https://github.com/Kabongosalomon/LiSTra).



## Credit

- [MaSS: A Large and Clean Multilingual Corpus of Sentence-aligned Spoken Utterances Extracted from the Bible](https://github.com/getalp/mass-dataset)
- [Yuchen Liu and al. paper](https://arxiv.org/pdf/1912.07240.pdf)


## Contact

You can contact me at kabongosalomon@gmail.com

