{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCW-xvckaO8s"
   },
   "source": [
    "# Live Colab Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T09:39:54.418700Z",
     "start_time": "2020-09-12T09:39:54.415303Z"
    },
    "id": "16gWjoEUXOhl"
   },
   "source": [
    "## Dependencies and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "\n",
    "!pip install -q omegaconf\n",
    "# !pip install -q torchaudio\n",
    "!pip install -q soundfile\n",
    "!pip install -q pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KabenamualuS\\Anaconda3\\envs\\ammi\\lib\\site-packages\\torchaudio\\extension\\extension.py:14: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "jc7ZqfooYZnD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KabenamualuS\\Anaconda3\\envs\\ammi\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import base64\n",
    "import tempfile\n",
    "import warnings\n",
    "import torchaudio\n",
    "\n",
    "from os.path import exists\n",
    "from glob import glob\n",
    "from omegaconf import OmegaConf\n",
    "from typing import List, Optional\n",
    "from itertools import groupby\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "torchaudio.set_audio_backend(\"soundfile\")  # switch backend\n",
    "\n",
    "def read_batch(audio_paths: List[str]):\n",
    "    return [read_audio(audio_path)\n",
    "            for audio_path\n",
    "            in audio_paths]\n",
    "\n",
    "\n",
    "def split_into_batches(lst: List[str],\n",
    "                       batch_size: int = 10):\n",
    "    return [lst[i:i + batch_size]\n",
    "            for i in\n",
    "            range(0, len(lst), batch_size)]\n",
    "\n",
    "\n",
    "def read_audio(path: str,\n",
    "               target_sr: int = 16000):\n",
    "\n",
    "    assert torchaudio.get_audio_backend() == 'soundfile'\n",
    "    wav, sr = torchaudio.load(path,\n",
    "                              normalization=True,\n",
    "                              channels_first=True)\n",
    "\n",
    "    if wav.size(0) > 1:\n",
    "        wav = wav.mean(dim=0, keepdim=True)\n",
    "\n",
    "    if sr != target_sr:\n",
    "        transform = torchaudio.transforms.Resample(orig_freq=sr,\n",
    "                                                   new_freq=target_sr)\n",
    "        wav = transform(wav)\n",
    "        sr = target_sr\n",
    "\n",
    "    assert sr == target_sr\n",
    "    return wav.squeeze(0)\n",
    "\n",
    "\n",
    "def prepare_model_input(batch: List[torch.Tensor],\n",
    "                        device=torch.device('cpu')):\n",
    "    \n",
    "    max_seqlength = max(max([len(_) for _ in batch]), 12800)\n",
    "    inputs = torch.zeros(len(batch), max_seqlength)\n",
    "    for i, wav in enumerate(batch):\n",
    "        inputs[i, :len(wav)].copy_(wav)\n",
    "    inputs = inputs.to(device)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class Decoder():\n",
    "    def __init__(self,\n",
    "                 labels: List[str]):\n",
    "        self.labels = labels\n",
    "        self.blank_idx = self.labels.index('_')\n",
    "\n",
    "    def process(self,\n",
    "                probs):\n",
    "        assert len(self.labels) == probs.shape[1]\n",
    "        for_string = []\n",
    "        argm = torch.argmax(probs, axis=1)\n",
    "        for i in argm:\n",
    "            if i == self.labels.index('2'):\n",
    "                try:\n",
    "                    prev = for_string[-1]\n",
    "                    for_string.append('$')\n",
    "                    for_string.append(prev)\n",
    "                    continue\n",
    "                except:\n",
    "                    for_string.append(' ')\n",
    "                    warnings.warn('Token \"2\" detected a the beginning of sentence, omitting')\n",
    "            if i != self.blank_idx:\n",
    "                for_string.append(self.labels[i])\n",
    "        string = ''.join([x[0] for x in groupby(for_string)]).replace('$', '').strip()\n",
    "        return string\n",
    "\n",
    "    def __call__(self,\n",
    "                 probs: torch.Tensor):\n",
    "        return self.process(probs)\n",
    "\n",
    "\n",
    "def init_jit_model(model_url: str,\n",
    "                   device: torch.device = torch.device('cpu')):\n",
    "    \n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile('wb', suffix='.model') as f:\n",
    "        torch.hub.download_url_to_file(model_url,\n",
    "                                       f.name,\n",
    "                                       progress=True)\n",
    "        model = torch.jit.load(f.name, map_location=device)\n",
    "        model.eval()\n",
    "    return model, Decoder(model.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# a modified version of this script https://github.com/magenta/ddsp/blob/master/ddsp/colab/colab_utils.py\n",
    "# modified in line with the rest of examples code\n",
    "#\n",
    "# from google.colab import files\n",
    "# from google.colab import output\n",
    "\n",
    "from IPython import display as _display\n",
    "\n",
    "\n",
    "def record_audio(seconds: int = 3,\n",
    "                 normalize_db: float = 0.1):\n",
    "    # Use Javascript to record audio.\n",
    "    record_js_code = \"\"\"\n",
    "      const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
    "      const b2text = blob => new Promise(resolve => {\n",
    "        const reader = new FileReader()\n",
    "        reader.onloadend = e => resolve(e.srcElement.result)\n",
    "        reader.readAsDataURL(blob)\n",
    "      })\n",
    "      var record = time => new Promise(async resolve => {\n",
    "        stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
    "        recorder = new MediaRecorder(stream)\n",
    "        chunks = []\n",
    "        recorder.ondataavailable = e => chunks.push(e.data)\n",
    "        recorder.start()\n",
    "        await sleep(time)\n",
    "        recorder.onstop = async ()=>{\n",
    "          blob = new Blob(chunks)\n",
    "          text = await b2text(blob)\n",
    "          resolve(text)\n",
    "        }\n",
    "        recorder.stop()\n",
    "      })\n",
    "      \"\"\"\n",
    "    print(f'Starting recording for {seconds} seconds...')\n",
    "    _display.display(_display.Javascript(record_js_code))\n",
    "    audio_string = output.eval_js('record(%d)' % (seconds * 1000.0))\n",
    "    print('Finished recording!')\n",
    "    audio_bytes = base64.b64decode(audio_string.split(',')[1])\n",
    "    return audio_bytes_to_np(audio_bytes,\n",
    "                             normalize_db=normalize_db)\n",
    "\n",
    "\n",
    "def audio_bytes_to_np(wav_data: bytes,\n",
    "                      normalize_db: float = 0.1):\n",
    "    # Parse and normalize the audio.\n",
    "    audio = AudioSegment.from_file(io.BytesIO(wav_data))\n",
    "    audio.remove_dc_offset()\n",
    "    if normalize_db is not None:\n",
    "        audio.normalize(headroom=normalize_db)\n",
    "    # Save to tempfile and load with librosa.\n",
    "    with tempfile.NamedTemporaryFile(suffix='.wav') as temp_wav_file:\n",
    "        fname = temp_wav_file.name\n",
    "        audio.export(fname, format='wav')\n",
    "        wav = read_audio(fname)\n",
    "    return wav\n",
    "\n",
    "\n",
    "def upload_audio(normalize_db: Optional[float] = None):\n",
    "    audio_files = files.upload()\n",
    "    fnames = list(audio_files.keys())\n",
    "    if len(fnames) == 0:\n",
    "        return None\n",
    "    return read_audio(fnames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "jc7ZqfooYZnD"
   },
   "outputs": [],
   "source": [
    "# from utils import (init_jit_model, \n",
    "#                    split_into_batches,\n",
    "#                    read_audio,\n",
    "#                    read_batch,\n",
    "#                    prepare_model_input)\n",
    "\n",
    "# from colab_utils import (record_audio,\n",
    "#                          audio_bytes_to_np,\n",
    "#                          upload_audio)\n",
    "\n",
    "device = torch.device('cpu')   # you can use any pytorch device\n",
    "models = OmegaConf.load('models.yml')\n",
    "\n",
    "# imports for uploading/recording\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio, display, clear_output\n",
    "from torchaudio.functional import vad\n",
    "\n",
    "\n",
    "# wav to text method\n",
    "def wav_to_text(f='test.wav'):\n",
    "    batch = read_batch([f])\n",
    "    input = prepare_model_input(batch, device=device)\n",
    "    output = model(input)\n",
    "    return decoder(output[0].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6QIeg7XffsO"
   },
   "source": [
    "## Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\KABENA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpm2eo780r.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\shutil.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\KABENA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpo7r7_8l0' -> 'C:\\\\Users\\\\KABENA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpm2eo780r.model'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-85c3d8264472>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_jit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstt_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-ddf4ad1f54a9>\u001b[0m in \u001b[0;36minit_jit_model\u001b[1;34m(model_url, device)\u001b[0m\n\u001b[0;32m     85\u001b[0m         torch.hub.download_url_to_file(model_url,\n\u001b[0;32m     86\u001b[0m                                        \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                                        progress=True)\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[1;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[0;32m    413\u001b[0m                 raise RuntimeError('invalid hash value (expected \"{}\", got \"{}\")'\n\u001b[0;32m    414\u001b[0m                                    .format(hash_prefix, digest))\n\u001b[1;32m--> 415\u001b[1;33m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\shutil.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[0mcopy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\KABENA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpm2eo780r.model'"
     ]
    }
   ],
   "source": [
    "model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "NJAOV1bbhEv0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3.4%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-eb1e15d6b6bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_jit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstt_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_jit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstt_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-ddf4ad1f54a9>\u001b[0m in \u001b[0;36minit_jit_model\u001b[1;34m(model_url, device)\u001b[0m\n\u001b[0;32m     85\u001b[0m         torch.hub.download_url_to_file(model_url,\n\u001b[0;32m     86\u001b[0m                                        \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                                        progress=True)\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[1;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mhash_prefix\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                     \u001b[0msha256\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m                 \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r{0:.1f} bytes\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r{0:.1f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[1;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    414\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    415\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ammi\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#@markdown { run: \"auto\" }\n",
    "\n",
    "language = \"English\" #@param [\"English\", \"German\", \"Spanish\"]\n",
    "\n",
    "print(language)\n",
    "if language == 'German':\n",
    "    model, decoder = init_jit_model(models.stt_models.de.latest.jit, device=device)\n",
    "elif language == \"Spanish\":\n",
    "    model, decoder = init_jit_model(models.stt_models.es.latest.jit, device=device)\n",
    "else:\n",
    "    model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "FYsz_90gTQh-"
   },
   "outputs": [],
   "source": [
    "#@markdown { run: \"auto\" }\n",
    "\n",
    "use_VAD = \"Yes\" #@param [\"Yes\", \"No\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "QttWasy5hUd6"
   },
   "outputs": [],
   "source": [
    "#@markdown Either record audio from microphone or upload audio from file (.mp3 or .wav) { run: \"auto\" }\n",
    "\n",
    "record_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
    "record_seconds = 4 #@param {type:\"number\", min:1, max:10, step:1}\n",
    "sample_rate = 16000\n",
    "\n",
    "def _apply_vad(audio, boot_time=0, trigger_level=9, **kwargs):\n",
    "    print('\\nVAD applied\\n')\n",
    "    vad_kwargs = dict(locals().copy(), **kwargs)\n",
    "    vad_kwargs['sample_rate'] = sample_rate\n",
    "    del vad_kwargs['kwargs'], vad_kwargs['audio']\n",
    "    audio = vad(torch.flip(audio, ([0])), **vad_kwargs)\n",
    "    return vad(torch.flip(audio, ([0])), **vad_kwargs)\n",
    "\n",
    "def _recognize(audio):\n",
    "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
    "    if use_VAD == \"Yes\":\n",
    "        audio = _apply_vad(audio)\n",
    "    wavfile.write('test.wav', sample_rate, (32767*audio).numpy().astype(np.int16))\n",
    "    transcription = wav_to_text()\n",
    "    print('\\n\\nTRANSCRIPTION:\\n')\n",
    "    print(transcription)\n",
    "\n",
    "def _record_audio(b):\n",
    "    clear_output()\n",
    "    audio = record_audio(record_seconds)\n",
    "    wavfile.write('recorded.wav', sample_rate, (32767*audio).numpy().astype(np.int16))\n",
    "    _recognize(audio)\n",
    "\n",
    "def _upload_audio(b):\n",
    "    clear_output()\n",
    "    audio = upload_audio()\n",
    "    _recognize(audio)\n",
    "    return audio\n",
    "\n",
    "if record_or_upload == \"Record\":\n",
    "    button = widgets.Button(description=\"Record Speech\")\n",
    "    button.on_click(_record_audio)\n",
    "    display(button)\n",
    "else:\n",
    "    audio = _upload_audio(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "E-bFGpn_TQiW"
   },
   "outputs": [],
   "source": [
    "#@markdown Check audio after applying VAD { run: \"auto\" }\n",
    "\n",
    "if record_or_upload == \"Record\":\n",
    "    audio = read_audio('recorded.wav', sample_rate)\n",
    "    \n",
    "display(Audio(_apply_vad(audio), rate=sample_rate, autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T13:31:58.954518Z",
     "start_time": "2020-09-11T13:31:58.952259Z"
    },
    "id": "nMkcU8sDXOh8"
   },
   "source": [
    "# PyTorch Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "xj7emOprcPQ6"
   },
   "outputs": [],
   "source": [
    "#@title Install Dependencies\n",
    "\n",
    "# this assumes that you have a relevant version of PyTorch installed\n",
    "!pip install -q torchaudio\n",
    "!pip install -q omegaconf\n",
    "!pip install -q soundfile\n",
    "\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "if not exists('silero-models'):\n",
    "    !git clone -q --depth 1 https://github.com/snakers4/silero-models\n",
    "\n",
    "%cd silero-models\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from glob import glob\n",
    "from omegaconf import OmegaConf\n",
    "from utils import (init_jit_model, \n",
    "                   split_into_batches,\n",
    "                   read_batch,\n",
    "                   prepare_model_input)\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "PXEfylBwbAYI"
   },
   "outputs": [],
   "source": [
    "#@title Random English Validation Dataset (optional)\n",
    "\n",
    "if not exists('scottish_english_female'):\n",
    "  !wget http://www.openslr.org/resources/83/scottish_english_female.zip\n",
    "  !unzip -qq scottish_english_female.zip -d scottish_english_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "dwSIJ6bmbAzq"
   },
   "outputs": [],
   "source": [
    "#@title Random Spanish Validation Dataset (optional)\n",
    "\n",
    "if not exists('es_pr_female'):\n",
    "  !wget http://www.openslr.org/resources/74/es_pr_female.zip\n",
    "  !unzip -qq es_pr_female.zip -d es_pr_female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8r3DW7IgkJil"
   },
   "source": [
    "## Example cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:21:25.234818Z",
     "start_time": "2020-09-11T14:21:25.218179Z"
    },
    "id": "GE0S5kmdXOiG"
   },
   "outputs": [],
   "source": [
    "models = OmegaConf.load('models.yml')  # all available models are listed in the yml file\n",
    "print(list(models.stt_models.keys()),\n",
    "      list(models.stt_models.en.keys()),\n",
    "      list(models.stt_models.en.latest.keys()),\n",
    "      models.stt_models.en.latest.jit)\n",
    "device = torch.device('cpu')   # you can use any pytorch device\n",
    "model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:21:26.056045Z",
     "start_time": "2020-09-11T14:21:26.040771Z"
    },
    "id": "GSUsZ7cqXOiL"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')   # you can use any pytorch device\n",
    "model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:25:14.996913Z",
     "start_time": "2020-09-11T14:21:40.831866Z"
    },
    "id": "paW8mugZXOiP"
   },
   "outputs": [],
   "source": [
    "# test_files = glob('path/to/your/file/*.opus')\n",
    "test_files = glob('scottish_english_female/*.wav')  # replace with your data\n",
    "batches = split_into_batches(test_files, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T13:57:09.061692Z",
     "start_time": "2020-09-11T13:57:08.992493Z"
    },
    "id": "JryVNe5hXOiR"
   },
   "outputs": [],
   "source": [
    "# transcribe a set of files\n",
    "input = prepare_model_input(read_batch(random.sample(batches, k=1)[0]),\n",
    "                            device=device)\n",
    "output = model(input)\n",
    "for example in output:\n",
    "    print(decoder(example.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T14:38:32.972790Z",
     "start_time": "2020-09-11T14:38:31.605231Z"
    },
    "id": "FgvdCQRSXOiY"
   },
   "outputs": [],
   "source": [
    "# listen to one file\n",
    "batch = read_batch(random.sample(batches, k=1)[0])\n",
    "input = prepare_model_input(batch,\n",
    "                            device=device)\n",
    "output = model(input)\n",
    "\n",
    "for i, example in enumerate(output):\n",
    "    print(decoder(example.cpu()))\n",
    "    display(Audio(batch[i], rate=16000))  # audio was resampled to 16kHz\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfa1Za1JUgUw"
   },
   "source": [
    "# ONNX Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "ku78lggJUm_3"
   },
   "outputs": [],
   "source": [
    "#@title Install and Import Dependencies\n",
    "\n",
    "# this assumes that you have a relevant version of PyTorch installed\n",
    "!pip install -q torchaudio omegaconf soundfile onnx onnxruntime\n",
    "\n",
    "import onnx\n",
    "import torch\n",
    "import onnxruntime\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i72mHSBbaG3p"
   },
   "source": [
    "## Example Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woxfbclsVl87"
   },
   "outputs": [],
   "source": [
    "language = 'en' # also available 'de', 'es'\n",
    "\n",
    "# load provided utils\n",
    "_, decoder, utils = torch.hub.load(github='snakers4/silero-models', model='silero_stt', language=language)\n",
    "(read_batch, split_into_batches,\n",
    " read_audio, prepare_model_input) = utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0ZLsWhpZFW6"
   },
   "outputs": [],
   "source": [
    "# see available models\n",
    "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml', 'models.yml')\n",
    "models = OmegaConf.load('models.yml')\n",
    "available_languages = list(models.stt_models.keys())\n",
    "assert language in available_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNbzvjU0ZHDm"
   },
   "outputs": [],
   "source": [
    "# load the actual ONNX model\n",
    "torch.hub.download_url_to_file(models.stt_models.en.latest.onnx, 'model.onnx', progress=True)\n",
    "onnx_model = onnx.load('model.onnx')\n",
    "onnx.checker.check_model(onnx_model)\n",
    "ort_session = onnxruntime.InferenceSession('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6sEQpptZJbF"
   },
   "outputs": [],
   "source": [
    "# download a single file, any format compatible with TorchAudio (soundfile backend)\n",
    "torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\n",
    "test_files = ['speech_orig.wav']\n",
    "batches = split_into_batches(test_files, batch_size=10)\n",
    "input = prepare_model_input(read_batch(batches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dkTVkkoYLCw"
   },
   "outputs": [],
   "source": [
    "# actual onnx inference and decoding\n",
    "onnx_input = input.detach().cpu().numpy()[0]\n",
    "ort_inputs = {'input': onnx_input}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "decoded = decoder(torch.Tensor(ort_outs[0]))\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0omBCDk5ZfBd"
   },
   "source": [
    "# TensorFlow Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "BmoBJY7QnC6P"
   },
   "outputs": [],
   "source": [
    "#@title Install and Import Dependencies\n",
    "\n",
    "# this assumes that you have a relevant version of PyTorch installed\n",
    "!pip install -q torchaudio omegaconf soundfile\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzTdtvQ-okUC"
   },
   "source": [
    "## Example cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eDUg9T5nX-l"
   },
   "outputs": [],
   "source": [
    "language = 'en' # also available 'de', 'es'\n",
    "\n",
    "# load provided utils using torch.hub for brevity\n",
    "_, decoder, utils = torch.hub.load(github='snakers4/silero-models', model='silero_stt', language=language)\n",
    "(read_batch, split_into_batches,\n",
    " read_audio, prepare_model_input) = utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGRwpCjfnroh"
   },
   "outputs": [],
   "source": [
    "# see available models\n",
    "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml', 'models.yml')\n",
    "models = OmegaConf.load('models.yml')\n",
    "available_languages = list(models.stt_models.keys())\n",
    "assert language in available_languages\n",
    "\n",
    "# load the actual tf model\n",
    "tf_model = tf_hub.load(models.stt_models.en.latest.tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nw-7LKEEoEIg"
   },
   "outputs": [],
   "source": [
    "# download a single file, any format compatible with TorchAudio (soundfile backend)\n",
    "torch.hub.download_url_to_file('https://opus-codec.org/static/examples/samples/speech_orig.wav', dst ='speech_orig.wav', progress=True)\n",
    "test_files = ['speech_orig.wav']\n",
    "batches = split_into_batches(test_files, batch_size=10)\n",
    "input = prepare_model_input(read_batch(batches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1__XOtFno1O"
   },
   "outputs": [],
   "source": [
    "# tf inference\n",
    "res = tf_model.signatures[\"serving_default\"](tf.constant(input.numpy()[0]))['output_0']\n",
    "print(decoder(torch.Tensor(res.numpy())))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab_examples.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ammi",
   "language": "python",
   "name": "ammi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
